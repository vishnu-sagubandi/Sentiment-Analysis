{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[1,3,2,4,3,2,3,4,1,3,4,1,2,2,3,2,2,2,3,2,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'Counter'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-32eee5365000>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCounter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'Counter'"
     ]
    }
   ],
   "source": [
    "a.Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 3, 3: 6, 2: 9, 4: 3})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats=Counter(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 3, 3: 6, 2: 9, 4: 3})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<itertools.chain at 0x140c1afeac8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.elements()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(stats.elements())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 3), (3, 6), (2, 9), (4, 3)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(stats.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cit=Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cit[\"w\"]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cit[\"e\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cit[\"e\"]=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cit[\"w\"]=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'e': 4, 'w': 3})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "myname=\"Vishnu is my name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Vishnu', 'is', 'my', 'name']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myname.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reviews=open('reviews.txt','r')\n",
    "print(reviews.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=\"POSITIVE\\n\"\n",
    "X=lambda x:x[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POSITIVE\n"
     ]
    }
   ],
   "source": [
    "print(X(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we have to convert text files into lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = open('reviews.txt','r')\n",
    "reviews = list(map(lambda x:x[:-1],g.readlines()))\n",
    "g.close()\n",
    "\n",
    "g = open('labels.txt','r')\n",
    "labels = list(map(lambda x:x[:-1].upper(),g.readlines()))\n",
    "g.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'POSITIVE'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bromwell high is a cartoon comedy . it ran at the same time as some other programs about school life  such as  teachers  . my   years in the teaching profession lead me to believe that bromwell high  s satire is much closer to reality than is  teachers  . the scramble to survive financially  the insightful students who can see right through their pathetic teachers  pomp  the pettiness of the whole situation  all remind me of the schools i knew and their students . when i saw the episode in which a student repeatedly tried to burn down the school  i immediately recalled . . . . . . . . . at . . . . . . . . . . high . a classic line inspector i  m here to sack one of your teachers . student welcome to bromwell high . i expect that many adults of my age think that bromwell high is far fetched . what a pity that it isn  t   '"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_vocab = set()\n",
    "for label in labels:\n",
    "    label_vocab.add(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NEGATIVE', 'POSITIVE'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_review_and_label(i):\n",
    "    print(labels[i] + \"\\t:\\t\" + reviews[i][:50] + \"...\")\n",
    "#This is just to check review and labels.So we are printing only upto 50 letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POSITIVE\t:\ti wasn  t sure what to expect but am i glad i went...\n",
      "POSITIVE\t:\tit was by accident that i was scanning the tv chan...\n",
      "NEGATIVE\t:\ti grew up on the  superman ii  theatrical version ...\n",
      "POSITIVE\t:\taro tolbukhin burnt alive seven people in a missio...\n",
      "POSITIVE\t:\tcypher is a movie well worth seeing because it  s ...\n",
      "NEGATIVE\t:\tcarly pope plays jj  a newly promoted food critic ...\n"
     ]
    }
   ],
   "source": [
    "print_review_and_label(1234)\n",
    "print_review_and_label(1000)\n",
    "print_review_and_label(123)\n",
    "print_review_and_label(50)\n",
    "print_review_and_label(2200)\n",
    "print_review_and_label(625)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class SentimentNetwork:\n",
    "    def __init__(self, reviews,labels,hidden_nodes = 10, learning_rate = 0.1):\n",
    "        # We are assigning a seed because to ensure to get reproducable results during development \n",
    "        np.random.seed(1)\n",
    "\n",
    "        self.pre_process_data(reviews, labels)\n",
    "        \n",
    "\n",
    "        self.init_network(len(self.review_vocab),hidden_nodes, 1, learning_rate)\n",
    "\n",
    "    def pre_process_data(self, reviews, labels):\n",
    "        \n",
    "        # vocab is set of all diff words that we input through training data \n",
    "        review_vocab = set()\n",
    "        for review in reviews:\n",
    "            for word in review.split(\" \"):\n",
    "                review_vocab.add(word)\n",
    "\n",
    "        # We will convert vocabulary set into list so we can access labels via indices\n",
    "        self.review_vocab = list(review_vocab)\n",
    "        \n",
    "        # Even though we know that there are are only two labels , we will prepare a set of labels again\n",
    "        label_vocab = set()\n",
    "        for label in labels:\n",
    "            label_vocab.add(label)\n",
    "        \n",
    "        # We will convert the label vocabulary set to a list\n",
    "        self.label_vocab = list(label_vocab)\n",
    "        \n",
    "        # Store the sizes of the review and label vocabularies.\n",
    "        self.review_vocab_size = len(self.review_vocab)\n",
    "        self.label_vocab_size = len(self.label_vocab)\n",
    "        \n",
    "        # Create a dictionary of words in the vocabulary\n",
    "        self.word2index = {}\n",
    "        for i, word in enumerate(self.review_vocab):\n",
    "            self.word2index[word] = i\n",
    "        \n",
    "        # Create a dictionary of labels\n",
    "        self.label2index = {}\n",
    "        for i, label in enumerate(self.label_vocab):\n",
    "            self.label2index[label] = i\n",
    "\n",
    "    def init_network(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
    "        # Set number of nodes in input, hidden and output layers.\n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "\n",
    "        # Store the learning rate\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        # Initialize weights\n",
    "\n",
    "        self.weights_0_1 = np.zeros((self.input_nodes,self.hidden_nodes))\n",
    "\n",
    "        self.weights_1_2 = np.random.normal(0.0, self.hidden_nodes**-0.5, \n",
    "                                                (self.hidden_nodes, self.output_nodes))\n",
    "        \n",
    "        #Input layer\n",
    "        self.layer_0 = np.zeros((1,input_nodes))        \n",
    "\n",
    "\n",
    "    def update_input_layer(self,review):\n",
    "\n",
    "        # This is to clear out previous state,So that we do not need to allocate new memory\n",
    "        #for next review which helps in conservation of memory and time\n",
    "        self.layer_0 *= 0\n",
    "        \n",
    "        for word in review.split(\" \"):\n",
    "            #   In testing data we might see some new words which may not present in training data \n",
    "            #   So, we will check whether the word is actually a key in word2index before accessing\n",
    "            #   it, which is important because accessing an invalid key might give an error.  \n",
    "            if(word in self.word2index.keys()):\n",
    "                self.layer_0[0][self.word2index[word]] = 1\n",
    "                \n",
    "    def get_target_for_label(self,label):\n",
    "        if(label == 'POSITIVE'):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def sigmoid(self,x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def sigmoid_output_2_derivative(self,output):\n",
    "        return output * (1 - output)\n",
    "    \n",
    "    def train(self, training_reviews, training_labels):\n",
    "        # First we will check whether no of reviws equal to no of labels\n",
    "        assert(len(training_reviews) == len(training_labels))\n",
    "        \n",
    "        # Remember when we started for printing time statistics\n",
    "        start = time.time()\n",
    "        correct_so_far=0\n",
    "        \n",
    "        # Implement forward and backward pass for every item\n",
    "        for i in range(len(training_reviews)):\n",
    "            \n",
    "            review = training_reviews[i]\n",
    "            label = training_labels[i]\n",
    "            \n",
    "            # Forward pass-->\n",
    "\n",
    "            # Input Layer\n",
    "            self.update_input_layer(review)\n",
    "\n",
    "            # Hidden layer\n",
    "            layer_1 = self.layer_0.dot(self.weights_0_1)\n",
    "\n",
    "            # Output layer\n",
    "            layer_2 = self.sigmoid(layer_1.dot(self.weights_1_2))\n",
    "            \n",
    "            # Backward pass<--\n",
    "\n",
    "            # Output error\n",
    "            layer_2_error = layer_2 - self.get_target_for_label(label)\n",
    "            layer_2_delta = layer_2_error * self.sigmoid_output_2_derivative(layer_2)\n",
    "\n",
    "            # Backpropagated error\n",
    "            layer_1_error = layer_2_delta.dot(self.weights_1_2.T) \n",
    "            layer_1_delta = layer_1_error \n",
    "\n",
    "            # Update the weights using gradient descent steps\n",
    "            self.weights_1_2 -= layer_1.T.dot(layer_2_delta) * self.learning_rate \n",
    "            self.weights_0_1 -= self.layer_0.T.dot(layer_1_delta) * self.learning_rate \n",
    "\n",
    "        \n",
    "            # Keep track of correct predictions.\n",
    "            if(layer_2 >= 0.5 and label == 'POSITIVE'):\n",
    "                correct_so_far += 1\n",
    "            elif(layer_2 < 0.5 and label == 'NEGATIVE'):\n",
    "                correct_so_far += 1\n",
    "\n",
    "            #Training Accuracy   \n",
    "            train_accuracy=correct_so_far * 100 / float(i+1)\n",
    "            \n",
    "            if i%1000==0:\n",
    "                print(\"Progress : {:.3f}% \\t\\t Accuracy : {:.3f}%\".format(i*100/len(training_reviews),train_accuracy))\n",
    "        print(\"Final train Accuracy  :  \"+str(train_accuracy))    \n",
    "    \n",
    "    def test(self, testing_reviews, testing_labels):\n",
    "        \n",
    "        # keep track of how many correct predictions we make\n",
    "        correct = 0\n",
    "\n",
    "\n",
    "        # Loop through each of the given reviews and call run to predict\n",
    "        # its label. \n",
    "        for i in range(len(testing_reviews)):\n",
    "            pred = self.run(testing_reviews[i])\n",
    "            if(pred == testing_labels[i]):\n",
    "                correct += 1\n",
    "            \n",
    "            test_accuracy=correct*100/float(i+1)\n",
    "            if i%100==0:\n",
    "                print(\"Progress : {:.3f}% \\t\\t Accuracy : {:.3f}%\".format(i*100/len(testing_reviews),test_accuracy))\n",
    "        print(\"Final test accuracy  :  \"+str(test_accuracy))   \n",
    "    \n",
    "    def run(self, review):\n",
    "        \n",
    "        # Input Layer\n",
    "        self.update_input_layer(review.lower())\n",
    "\n",
    "        # Hidden layer\n",
    "        layer_1 = self.layer_0.dot(self.weights_0_1)\n",
    "\n",
    "        # Output layer\n",
    "        layer_2 = self.sigmoid(layer_1.dot(self.weights_1_2))\n",
    "        \n",
    "        # Return POSITIVE for values above greater-than-or-equal-to 0.5 in the output layer;\n",
    "        # return NEGATIVE for other values\n",
    "        if(layer_2[0] >= 0.5):\n",
    "            return \"POSITIVE\"\n",
    "        else:\n",
    "            return \"NEGATIVE\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress : 0.000% \t\t Accuracy : 100.000%\n",
      "Progress : 4.167% \t\t Accuracy : 74.426%\n",
      "Progress : 8.333% \t\t Accuracy : 77.011%\n",
      "Progress : 12.500% \t\t Accuracy : 79.174%\n",
      "Progress : 16.667% \t\t Accuracy : 79.555%\n",
      "Progress : 20.833% \t\t Accuracy : 79.864%\n",
      "Progress : 25.000% \t\t Accuracy : 80.520%\n",
      "Progress : 29.167% \t\t Accuracy : 81.417%\n",
      "Progress : 33.333% \t\t Accuracy : 81.890%\n",
      "Progress : 37.500% \t\t Accuracy : 82.302%\n",
      "Progress : 41.667% \t\t Accuracy : 82.772%\n",
      "Progress : 45.833% \t\t Accuracy : 83.074%\n",
      "Progress : 50.000% \t\t Accuracy : 83.343%\n",
      "Progress : 54.167% \t\t Accuracy : 83.609%\n",
      "Progress : 58.333% \t\t Accuracy : 83.830%\n",
      "Progress : 62.500% \t\t Accuracy : 83.861%\n",
      "Progress : 66.667% \t\t Accuracy : 83.807%\n",
      "Progress : 70.833% \t\t Accuracy : 83.883%\n",
      "Progress : 75.000% \t\t Accuracy : 84.012%\n",
      "Progress : 79.167% \t\t Accuracy : 84.185%\n",
      "Progress : 83.333% \t\t Accuracy : 84.336%\n",
      "Progress : 87.500% \t\t Accuracy : 84.477%\n",
      "Progress : 91.667% \t\t Accuracy : 84.655%\n",
      "Progress : 95.833% \t\t Accuracy : 84.709%\n",
      "Final train Accuracy  :  84.89583333333333\n"
     ]
    }
   ],
   "source": [
    "mlp = SentimentNetwork(reviews[:-1000],labels[:-1000], learning_rate=0.1)\n",
    "mlp.train(reviews[:-1000],labels[:-1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress : 0.000% \t\t Accuracy : 100.000%\n",
      "Progress : 10.000% \t\t Accuracy : 91.089%\n",
      "Progress : 20.000% \t\t Accuracy : 88.557%\n",
      "Progress : 30.000% \t\t Accuracy : 89.037%\n",
      "Progress : 40.000% \t\t Accuracy : 87.531%\n",
      "Progress : 50.000% \t\t Accuracy : 88.224%\n",
      "Progress : 60.000% \t\t Accuracy : 88.686%\n",
      "Progress : 70.000% \t\t Accuracy : 87.019%\n",
      "Progress : 80.000% \t\t Accuracy : 86.017%\n",
      "Progress : 90.000% \t\t Accuracy : 86.238%\n",
      "Final test accuracy  :  86.0\n"
     ]
    }
   ],
   "source": [
    "mlp.test(reviews[-1000:],labels[-1000:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My first neural network project completed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even you can use no.of epochs for better accuracy.I had not taken since 25,000 observations in huge number and it might take longer time for training to run on cpu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
